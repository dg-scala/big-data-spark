Your overall score for this assignment is 2.86 out of 10.00


The code you submitted did not pass all of our tests: your submission achieved a score of
2.86 out of 10.00 in our tests.

In order to find bugs in your code, we advise to perform the following steps:
 - Take a close look at the test output that you can find below: it should point you to
   the part of your code that has bugs.
 - Run the tests that we provide with the handout on your code.
 - The tests we provide do not test your code in depth: they are very incomplete. In order
   to test more aspects of your code, write your own unit tests.
 - Take another very careful look at the assignment description. Try to find out if you
   misunderstood parts of it. While reading through the assignment, write more tests.

Below you can find a short feedback for every individual test that failed.

======== LOG OF FAILED TESTS ========
Your solution achieved a testing score of 4 out of 14.

Below you can see a short feedback for every test that failed,
indicating the reason for the test failure and how many points
you lost for each individual test.

Tests that were aborted took too long too complete or crashed the
JVM. Such crashes can arise due to infinite non-terminating
loops or recursion (StackOverflowException) or excessive memory
consumption (OutOfMemoryException).

[Test Description] 'rankLangsUsingIndex' run on a subset of the dataset provided in object `WikipediaData` returns the correct ranking (in descending order)
[Observed Error] an implementation is missing
[exception was thrown] detailed error message in debug output section below
[Lost Points] 1

[Test Description] 'makeIndex' creates a simple index with two entries
[Observed Error] an implementation is missing
[exception was thrown] detailed error message in debug output section below
[Lost Points] 1

[Test Description] 'rankLangsUsingIndex' should work for a simple RDD with three elements
[Observed Error] an implementation is missing
[exception was thrown] detailed error message in debug output section below
[Lost Points] 1

[Test Description] 'rankLangs' run on the dataset provided in object `WikipediaData` returns the correct ranking (in descending order)
[Observed Error] res was false
[Lost Points] 1

[Test Description] 'rankLangsReduceByKey' should work for a simple RDD with five elements
[Observed Error] an implementation is missing
[exception was thrown] detailed error message in debug output section below
[Lost Points] 1

[Test Description] 'makeIndex' run on the dataset provided in object `WikipediaData` returns correct language-article mappings
[Observed Error] an implementation is missing
[exception was thrown] detailed error message in debug output section below
[Lost Points] 1

[Test Description] 'rankLangsReduceByKey' run on the dataset provided in object `WikipediaData` returns the correct ranking (in descending order)
[Observed Error] an implementation is missing
[exception was thrown] detailed error message in debug output section below
[Lost Points] 1

[Test Description] 'rankLangs' run on a subset of the dataset provided in object `WikipediaData` returns the correct ranking (in descending order)
[Observed Error] res was false
[Lost Points] 1

[Test Description] 'rankLangsUsingIndex' run on the dataset provided in object `WikipediaData` returns the correct ranking (in descending order)
[Observed Error] an implementation is missing
[exception was thrown] detailed error message in debug output section below
[Lost Points] 1

[Test Description] 'rankLangsReduceByKey' run on a subset of the dataset provided in object `WikipediaData` returns the correct ranking (in descending order)
[Observed Error] an implementation is missing
[exception was thrown] detailed error message in debug output section below
[Lost Points] 1

======== TESTING ENVIRONMENT ========
Limits: memory: 1540m,  total time: 900s,  per test case time: 240s

======== DEBUG OUTPUT OF TESTING TOOL ========
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/03/12 16:04:57 INFO SparkContext: Running Spark version 2.0.0
17/03/12 16:04:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/03/12 16:04:57 INFO SecurityManager: Changing view acls to: grader
17/03/12 16:04:57 INFO SecurityManager: Changing modify acls to: grader
17/03/12 16:04:57 INFO SecurityManager: Changing view acls groups to:
17/03/12 16:04:57 INFO SecurityManager: Changing modify acls groups to:
17/03/12 16:04:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(grader); groups with view permissions: Set(); users  with modify permissions: Set(grader); groups with modify permissions: Set()
17/03/12 16:04:58 INFO Utils: Successfully started service 'sparkDriver' on port 51341.
17/03/12 16:04:58 INFO SparkEnv: Registering MapOutputTracker
17/03/12 16:04:58 INFO SparkEnv: Registering BlockManagerMaster
17/03/12 16:04:58 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5c459dc0-9b46-4136-8eed-09cb58bb193e
17/03/12 16:04:58 INFO MemoryStore: MemoryStore started with capacity 641.4 MB
17/03/12 16:04:58 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/12 16:04:58 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/03/12 16:04:58 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/03/12 16:04:59 INFO Executor: Starting executor ID driver on host localhost
17/03/12 16:04:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60609.
17/03/12 16:04:59 INFO NettyBlockTransferService: Server created on 127.0.0.1:60609
17/03/12 16:04:59 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 60609)
17/03/12 16:04:59 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:60609 with 641.4 MB RAM, BlockManagerId(driver, 127.0.0.1, 60609)
17/03/12 16:04:59 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 60609)
17/03/12 16:05:00 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 641.3 MB)
17/03/12 16:05:00 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KB, free 641.3 MB)
17/03/12 16:05:00 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:60609 (size: 10.2 KB, free: 641.4 MB)
17/03/12 16:05:00 INFO SparkContext: Created broadcast 0 from textFile at WikipediaRanking.scala:24
17/03/12 16:05:00 INFO SparkContext: Starting job: aggregate at WikipediaRanking.scala:35
17/03/12 16:05:00 INFO DAGScheduler: Got job 0 (aggregate at WikipediaRanking.scala:35) with 2 output partitions
17/03/12 16:05:00 INFO DAGScheduler: Final stage: ResultStage 0 (aggregate at WikipediaRanking.scala:35)
17/03/12 16:05:00 INFO DAGScheduler: Parents of final stage: List()
17/03/12 16:05:00 INFO DAGScheduler: Missing parents: List()
17/03/12 16:05:00 INFO DAGScheduler: Submitting ResultStage 0 (ParallelCollectionRDD[3] at parallelize at WikipediaSuite.scala:50), which has no missing parents
17/03/12 16:05:00 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 1928.0 B, free 641.3 MB)
17/03/12 16:05:00 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 1263.0 B, free 641.3 MB)
17/03/12 16:05:00 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:60609 (size: 1263.0 B, free: 641.4 MB)
17/03/12 16:05:00 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1012
17/03/12 16:05:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (ParallelCollectionRDD[3] at parallelize at WikipediaSuite.scala:50)
17/03/12 16:05:00 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
17/03/12 16:05:00 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5341 bytes)
17/03/12 16:05:00 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1, PROCESS_LOCAL, 5432 bytes)
17/03/12 16:05:00 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/12 16:05:00 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/12 16:05:00 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 793 bytes result sent to driver
17/03/12 16:05:00 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 793 bytes result sent to driver
17/03/12 16:05:00 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 121 ms on localhost (1/2)
17/03/12 16:05:00 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 81 ms on localhost (2/2)
17/03/12 16:05:00 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
17/03/12 16:05:00 INFO DAGScheduler: ResultStage 0 (aggregate at WikipediaRanking.scala:35) finished in 0.149 s
17/03/12 16:05:00 INFO DAGScheduler: Job 0 finished: aggregate at WikipediaRanking.scala:35, took 0.273456 s
17/03/12 16:05:00 INFO SparkContext: Starting job: aggregate at WikipediaRanking.scala:35
17/03/12 16:05:00 INFO DAGScheduler: Got job 1 (aggregate at WikipediaRanking.scala:35) with 2 output partitions
17/03/12 16:05:00 INFO DAGScheduler: Final stage: ResultStage 1 (aggregate at WikipediaRanking.scala:35)
17/03/12 16:05:00 INFO DAGScheduler: Parents of final stage: List()
17/03/12 16:05:00 INFO DAGScheduler: Missing parents: List()
17/03/12 16:05:00 INFO DAGScheduler: Submitting ResultStage 1 (ParallelCollectionRDD[4] at parallelize at WikipediaSuite.scala:63), which has no missing parents
17/03/12 16:05:00 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 1928.0 B, free 641.3 MB)
17/03/12 16:05:00 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 1263.0 B, free 641.3 MB)
17/03/12 16:05:00 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:60609 (size: 1263.0 B, free: 641.4 MB)
17/03/12 16:05:00 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1012
17/03/12 16:05:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (ParallelCollectionRDD[4] at parallelize at WikipediaSuite.scala:63)
17/03/12 16:05:00 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
17/03/12 16:05:00 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:00 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1, PROCESS_LOCAL, 5447 bytes)
17/03/12 16:05:00 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
17/03/12 16:05:00 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
17/03/12 16:05:00 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 793 bytes result sent to driver
17/03/12 16:05:00 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 714 bytes result sent to driver
17/03/12 16:05:00 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 13 ms on localhost (1/2)
17/03/12 16:05:00 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 12 ms on localhost (2/2)
17/03/12 16:05:00 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
17/03/12 16:05:00 INFO DAGScheduler: ResultStage 1 (aggregate at WikipediaRanking.scala:35) finished in 0.014 s
17/03/12 16:05:00 INFO DAGScheduler: Job 1 finished: aggregate at WikipediaRanking.scala:35, took 0.023287 s
17/03/12 16:05:00 INFO SparkContext: Starting job: aggregate at WikipediaRanking.scala:35
17/03/12 16:05:00 INFO DAGScheduler: Got job 2 (aggregate at WikipediaRanking.scala:35) with 2 output partitions
17/03/12 16:05:00 INFO DAGScheduler: Final stage: ResultStage 2 (aggregate at WikipediaRanking.scala:35)
17/03/12 16:05:00 INFO DAGScheduler: Parents of final stage: List()
17/03/12 16:05:00 INFO DAGScheduler: Missing parents: List()
17/03/12 16:05:00 INFO DAGScheduler: Submitting ResultStage 2 (ParallelCollectionRDD[4] at parallelize at WikipediaSuite.scala:63), which has no missing parents
17/03/12 16:05:00 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 1928.0 B, free 641.3 MB)
17/03/12 16:05:00 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 1263.0 B, free 641.3 MB)
17/03/12 16:05:00 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:60609 (size: 1263.0 B, free: 641.4 MB)
17/03/12 16:05:00 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1012
17/03/12 16:05:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (ParallelCollectionRDD[4] at parallelize at WikipediaSuite.scala:63)
17/03/12 16:05:00 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
17/03/12 16:05:00 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:00 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, partition 1, PROCESS_LOCAL, 5447 bytes)
17/03/12 16:05:00 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
17/03/12 16:05:00 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
17/03/12 16:05:00 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 793 bytes result sent to driver
17/03/12 16:05:00 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 714 bytes result sent to driver
17/03/12 16:05:00 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 9 ms on localhost (1/2)
17/03/12 16:05:00 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 8 ms on localhost (2/2)
17/03/12 16:05:00 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
17/03/12 16:05:00 INFO DAGScheduler: ResultStage 2 (aggregate at WikipediaRanking.scala:35) finished in 0.011 s
17/03/12 16:05:00 INFO DAGScheduler: Job 2 finished: aggregate at WikipediaRanking.scala:35, took 0.018148 s
[test failure log] test name: WikipediaSuite::'makeIndex' creates a simple index with two entries::1
scala.NotImplementedError: an implementation is missing
scala.Predef$.$qmark$qmark$qmark(Predef.scala:230)
wikipedia.WikipediaRanking$.makeIndex(WikipediaRanking.scala:61)
wikipedia.WikipediaSuite$$anonfun$3.apply$mcV$sp(WikipediaSuite.scala:83)
ch.epfl.lamp.grading.GradingSuite$$anonfun$test$1.apply$mcV$sp(GradingSuite.scala:118)
ch.epfl.lamp.grading.GradingSuite$$anonfun$test$1.apply(GradingSuite.scala:117)
ch.epfl.lamp.grading.GradingSuite$$anonfun$test$1.apply(GradingSuite.scala:117)
org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
org.scalatest.Transformer.apply(Transformer.scala:22)
org.scalatest.Transformer.apply(Transformer.scala:20)
org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
org.scalatest.Suite$class.withFixture(Suite.scala:1122)
org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
scala.collection.immutable.List.foreach(List.scala:381)


[test failure log] test name: WikipediaSuite::'rankLangsUsingIndex' should work for a simple RDD with three elements::1
scala.NotImplementedError: an implementation is missing
scala.Predef$.$qmark$qmark$qmark(Predef.scala:230)
wikipedia.WikipediaRanking$.makeIndex(WikipediaRanking.scala:61)
wikipedia.WikipediaSuite$$anonfun$4.apply$mcV$sp(WikipediaSuite.scala:102)
ch.epfl.lamp.grading.GradingSuite$$anonfun$test$1.apply$mcV$sp(GradingSuite.scala:118)
ch.epfl.lamp.grading.GradingSuite$$anonfun$test$1.apply(GradingSuite.scala:117)
ch.epfl.lamp.grading.GradingSuite$$anonfun$test$1.apply(GradingSuite.scala:117)
org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
org.scalatest.Transformer.apply(Transformer.scala:22)
org.scalatest.Transformer.apply(Transformer.scala:20)
org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
org.scalatest.Suite$class.withFixture(Suite.scala:1122)
org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
scala.collection.immutable.List.foreach(List.scala:381)


[test failure log] test name: WikipediaSuite::'rankLangsReduceByKey' should work for a simple RDD with five elements::1
scala.NotImplementedError: an implementation is missing
scala.Predef$.$qmark$qmark$qmark(Predef.scala:230)
wikipedia.WikipediaRanking$.rankLangsReduceByKey(WikipediaRanking.scala:78)
wikipedia.WikipediaSuite$$anonfun$5.apply$mcV$sp(WikipediaSuite.scala:124)
ch.epfl.lamp.grading.GradingSuite$$anonfun$test$1.apply$mcV$sp(GradingSuite.scala:118)
ch.epfl.lamp.grading.GradingSuite$$anonfun$test$1.apply(GradingSuite.scala:117)
ch.epfl.lamp.grading.GradingSuite$$anonfun$test$1.apply(GradingSuite.scala:117)
org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
org.scalatest.Transformer.apply(Transformer.scala:22)
org.scalatest.Transformer.apply(Transformer.scala:20)
org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
org.scalatest.Suite$class.withFixture(Suite.scala:1122)
org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
scala.collection.immutable.List.foreach(List.scala:381)


17/03/12 16:05:00 INFO SparkContext: Starting job: aggregate at WikipediaRanking.scala:35
17/03/12 16:05:00 INFO DAGScheduler: Got job 3 (aggregate at WikipediaRanking.scala:35) with 2 output partitions
17/03/12 16:05:00 INFO DAGScheduler: Final stage: ResultStage 3 (aggregate at WikipediaRanking.scala:35)
17/03/12 16:05:00 INFO DAGScheduler: Parents of final stage: List()
17/03/12 16:05:00 INFO DAGScheduler: Missing parents: List()
17/03/12 16:05:00 INFO DAGScheduler: Submitting ResultStage 3 (ParallelCollectionRDD[8] at parallelize at WikipediaSuite.scala:134), which has no missing parents
17/03/12 16:05:00 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 1928.0 B, free 641.3 MB)
17/03/12 16:05:00 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 1263.0 B, free 641.3 MB)
17/03/12 16:05:00 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:60609 (size: 1263.0 B, free: 641.4 MB)
17/03/12 16:05:00 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1012
17/03/12 16:05:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 3 (ParallelCollectionRDD[8] at parallelize at WikipediaSuite.scala:134)
17/03/12 16:05:00 INFO TaskSchedulerImpl: Adding task set 3.0 with 2 tasks
17/03/12 16:05:00 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5342 bytes)
17/03/12 16:05:00 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, partition 1, PROCESS_LOCAL, 5342 bytes)
17/03/12 16:05:00 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
17/03/12 16:05:00 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
17/03/12 16:05:00 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 714 bytes result sent to driver
17/03/12 16:05:00 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 714 bytes result sent to driver
17/03/12 16:05:00 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 7 ms on localhost (1/2)
17/03/12 16:05:00 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 9 ms on localhost (2/2)
17/03/12 16:05:00 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
17/03/12 16:05:00 INFO DAGScheduler: ResultStage 3 (aggregate at WikipediaRanking.scala:35) finished in 0.011 s
17/03/12 16:05:00 INFO DAGScheduler: Job 3 finished: aggregate at WikipediaRanking.scala:35, took 0.018547 s
17/03/12 16:05:00 INFO SparkContext: Starting job: aggregate at WikipediaRanking.scala:35
17/03/12 16:05:00 INFO DAGScheduler: Got job 4 (aggregate at WikipediaRanking.scala:35) with 2 output partitions
17/03/12 16:05:00 INFO DAGScheduler: Final stage: ResultStage 4 (aggregate at WikipediaRanking.scala:35)
17/03/12 16:05:00 INFO DAGScheduler: Parents of final stage: List()
17/03/12 16:05:00 INFO DAGScheduler: Missing parents: List()
17/03/12 16:05:00 INFO DAGScheduler: Submitting ResultStage 4 (ParallelCollectionRDD[9] at parallelize at WikipediaSuite.scala:142), which has no missing parents
17/03/12 16:05:00 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 1928.0 B, free 641.3 MB)
17/03/12 16:05:00 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 1263.0 B, free 641.3 MB)
17/03/12 16:05:00 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:60609 (size: 1263.0 B, free: 641.4 MB)
17/03/12 16:05:00 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1012
17/03/12 16:05:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (ParallelCollectionRDD[9] at parallelize at WikipediaSuite.scala:142)
17/03/12 16:05:00 INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks
17/03/12 16:05:00 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5342 bytes)
17/03/12 16:05:00 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 9, localhost, partition 1, PROCESS_LOCAL, 5433 bytes)
17/03/12 16:05:00 INFO Executor: Running task 1.0 in stage 4.0 (TID 9)
17/03/12 16:05:00 INFO Executor: Running task 0.0 in stage 4.0 (TID 8)
17/03/12 16:05:00 INFO Executor: Finished task 1.0 in stage 4.0 (TID 9). 714 bytes result sent to driver
17/03/12 16:05:00 INFO Executor: Finished task 0.0 in stage 4.0 (TID 8). 793 bytes result sent to driver
17/03/12 16:05:00 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 9) in 6 ms on localhost (1/2)
17/03/12 16:05:00 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 8) in 9 ms on localhost (2/2)
17/03/12 16:05:00 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
17/03/12 16:05:00 INFO DAGScheduler: ResultStage 4 (aggregate at WikipediaRanking.scala:35) finished in 0.010 s
17/03/12 16:05:00 INFO DAGScheduler: Job 4 finished: aggregate at WikipediaRanking.scala:35, took 0.017425 s
17/03/12 16:05:00 INFO FileInputFormat: Total input paths to process : 1
17/03/12 16:05:00 INFO SparkContext: Starting job: aggregate at WikipediaRanking.scala:35
17/03/12 16:05:00 INFO DAGScheduler: Got job 5 (aggregate at WikipediaRanking.scala:35) with 3 output partitions
17/03/12 16:05:00 INFO DAGScheduler: Final stage: ResultStage 5 (aggregate at WikipediaRanking.scala:35)
17/03/12 16:05:00 INFO DAGScheduler: Parents of final stage: List()
17/03/12 16:05:00 INFO DAGScheduler: Missing parents: List()
17/03/12 16:05:00 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[2] at map at WikipediaRanking.scala:25), which has no missing parents
17/03/12 16:05:00 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 3.8 KB, free 641.3 MB)
17/03/12 16:05:00 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.2 KB, free 641.3 MB)
17/03/12 16:05:00 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:60609 (size: 2.2 KB, free: 641.4 MB)
17/03/12 16:05:00 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1012
17/03/12 16:05:00 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 5 (MapPartitionsRDD[2] at map at WikipediaRanking.scala:25)
17/03/12 16:05:00 INFO TaskSchedulerImpl: Adding task set 5.0 with 3 tasks
17/03/12 16:05:00 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 10, localhost, partition 0, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:00 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 11, localhost, partition 1, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:00 INFO Executor: Running task 0.0 in stage 5.0 (TID 10)
17/03/12 16:05:00 INFO Executor: Running task 1.0 in stage 5.0 (TID 11)
17/03/12 16:05:01 INFO HadoopRDD: Input split: file:/grader/repository/courses/bigdata/target/scala-2.11/classes/wikipedia/wikipedia.dat:0+33554432
17/03/12 16:05:01 INFO HadoopRDD: Input split: file:/grader/repository/courses/bigdata/target/scala-2.11/classes/wikipedia/wikipedia.dat:33554432+33554432
17/03/12 16:05:01 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/03/12 16:05:01 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/03/12 16:05:01 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
17/03/12 16:05:01 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
17/03/12 16:05:01 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
17/03/12 16:05:01 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
17/03/12 16:05:01 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:60609 in memory (size: 1263.0 B, free: 641.4 MB)
17/03/12 16:05:01 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:60609 in memory (size: 1263.0 B, free: 641.4 MB)
17/03/12 16:05:01 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:60609 in memory (size: 1263.0 B, free: 641.4 MB)
17/03/12 16:05:01 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:60609 in memory (size: 1263.0 B, free: 641.4 MB)
17/03/12 16:05:01 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:60609 in memory (size: 1263.0 B, free: 641.4 MB)
17/03/12 16:05:01 INFO MemoryStore: Block rdd_2_1 stored as values in memory (estimated size 55.1 MB, free 586.1 MB)
17/03/12 16:05:01 INFO BlockManagerInfo: Added rdd_2_1 in memory on 127.0.0.1:60609 (size: 55.1 MB, free: 586.2 MB)
17/03/12 16:05:01 INFO Executor: Finished task 1.0 in stage 5.0 (TID 11). 1798 bytes result sent to driver
17/03/12 16:05:01 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 12, localhost, partition 2, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:01 INFO Executor: Running task 2.0 in stage 5.0 (TID 12)
17/03/12 16:05:01 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 11) in 709 ms on localhost (1/3)
17/03/12 16:05:01 INFO HadoopRDD: Input split: file:/grader/repository/courses/bigdata/target/scala-2.11/classes/wikipedia/wikipedia.dat:67108864+3809363
17/03/12 16:05:01 INFO MemoryStore: Block rdd_2_0 stored as values in memory (estimated size 61.0 MB, free 525.1 MB)
17/03/12 16:05:01 INFO BlockManagerInfo: Added rdd_2_0 in memory on 127.0.0.1:60609 (size: 61.0 MB, free: 525.2 MB)
17/03/12 16:05:01 INFO Executor: Finished task 0.0 in stage 5.0 (TID 10). 1711 bytes result sent to driver
17/03/12 16:05:01 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 10) in 739 ms on localhost (2/3)
17/03/12 16:05:01 INFO MemoryStore: Block rdd_2_2 stored as values in memory (estimated size 7.1 MB, free 518.0 MB)
17/03/12 16:05:01 INFO BlockManagerInfo: Added rdd_2_2 in memory on 127.0.0.1:60609 (size: 7.1 MB, free: 518.1 MB)
17/03/12 16:05:01 INFO Executor: Finished task 2.0 in stage 5.0 (TID 12). 1638 bytes result sent to driver
17/03/12 16:05:01 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 12) in 44 ms on localhost (3/3)
17/03/12 16:05:01 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
17/03/12 16:05:01 INFO DAGScheduler: ResultStage 5 (aggregate at WikipediaRanking.scala:35) finished in 0.763 s
17/03/12 16:05:01 INFO DAGScheduler: Job 5 finished: aggregate at WikipediaRanking.scala:35, took 0.779179 s
17/03/12 16:05:01 INFO SparkContext: Starting job: aggregate at WikipediaRanking.scala:35
17/03/12 16:05:01 INFO DAGScheduler: Got job 6 (aggregate at WikipediaRanking.scala:35) with 3 output partitions
17/03/12 16:05:01 INFO DAGScheduler: Final stage: ResultStage 6 (aggregate at WikipediaRanking.scala:35)
17/03/12 16:05:01 INFO DAGScheduler: Parents of final stage: List()
17/03/12 16:05:01 INFO DAGScheduler: Missing parents: List()
17/03/12 16:05:01 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[2] at map at WikipediaRanking.scala:25), which has no missing parents
17/03/12 16:05:01 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 3.8 KB, free 518.0 MB)
17/03/12 16:05:01 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.2 KB, free 518.0 MB)
17/03/12 16:05:01 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:60609 (size: 2.2 KB, free: 518.1 MB)
17/03/12 16:05:01 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1012
17/03/12 16:05:01 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 6 (MapPartitionsRDD[2] at map at WikipediaRanking.scala:25)
17/03/12 16:05:01 INFO TaskSchedulerImpl: Adding task set 6.0 with 3 tasks
17/03/12 16:05:01 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 13, localhost, partition 0, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:01 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 14, localhost, partition 1, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:01 INFO Executor: Running task 0.0 in stage 6.0 (TID 13)
17/03/12 16:05:01 INFO Executor: Running task 1.0 in stage 6.0 (TID 14)
17/03/12 16:05:01 INFO BlockManager: Found block rdd_2_1 locally
17/03/12 16:05:01 INFO BlockManager: Found block rdd_2_0 locally
17/03/12 16:05:03 INFO Executor: Finished task 0.0 in stage 6.0 (TID 13). 953 bytes result sent to driver
17/03/12 16:05:03 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 15, localhost, partition 2, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO Executor: Running task 2.0 in stage 6.0 (TID 15)
17/03/12 16:05:03 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 13) in 1320 ms on localhost (1/3)
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_2 locally
17/03/12 16:05:03 INFO Executor: Finished task 1.0 in stage 6.0 (TID 14). 953 bytes result sent to driver
17/03/12 16:05:03 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 14) in 1320 ms on localhost (2/3)
17/03/12 16:05:03 INFO Executor: Finished task 2.0 in stage 6.0 (TID 15). 953 bytes result sent to driver
17/03/12 16:05:03 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 15) in 130 ms on localhost (3/3)
17/03/12 16:05:03 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
17/03/12 16:05:03 INFO DAGScheduler: ResultStage 6 (aggregate at WikipediaRanking.scala:35) finished in 1.450 s
17/03/12 16:05:03 INFO DAGScheduler: Job 6 finished: aggregate at WikipediaRanking.scala:35, took 1.466283 s
17/03/12 16:05:03 INFO SparkContext: Starting job: aggregate at WikipediaRanking.scala:35
17/03/12 16:05:03 INFO DAGScheduler: Got job 7 (aggregate at WikipediaRanking.scala:35) with 3 output partitions
17/03/12 16:05:03 INFO DAGScheduler: Final stage: ResultStage 7 (aggregate at WikipediaRanking.scala:35)
17/03/12 16:05:03 INFO DAGScheduler: Parents of final stage: List()
17/03/12 16:05:03 INFO DAGScheduler: Missing parents: List()
17/03/12 16:05:03 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[2] at map at WikipediaRanking.scala:25), which has no missing parents
17/03/12 16:05:03 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 3.8 KB, free 518.0 MB)
17/03/12 16:05:03 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.2 KB, free 518.0 MB)
17/03/12 16:05:03 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:60609 (size: 2.2 KB, free: 518.1 MB)
17/03/12 16:05:03 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1012
17/03/12 16:05:03 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 7 (MapPartitionsRDD[2] at map at WikipediaRanking.scala:25)
17/03/12 16:05:03 INFO TaskSchedulerImpl: Adding task set 7.0 with 3 tasks
17/03/12 16:05:03 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 16, localhost, partition 0, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 17, localhost, partition 1, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO Executor: Running task 0.0 in stage 7.0 (TID 16)
17/03/12 16:05:03 INFO Executor: Running task 1.0 in stage 7.0 (TID 17)
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_1 locally
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_0 locally
17/03/12 16:05:03 INFO Executor: Finished task 1.0 in stage 7.0 (TID 17). 953 bytes result sent to driver
17/03/12 16:05:03 INFO Executor: Finished task 0.0 in stage 7.0 (TID 16). 953 bytes result sent to driver
17/03/12 16:05:03 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 18, localhost, partition 2, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO Executor: Running task 2.0 in stage 7.0 (TID 18)
17/03/12 16:05:03 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 17) in 19 ms on localhost (1/3)
17/03/12 16:05:03 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 16) in 20 ms on localhost (2/3)
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_2 locally
17/03/12 16:05:03 INFO Executor: Finished task 2.0 in stage 7.0 (TID 18). 953 bytes result sent to driver
17/03/12 16:05:03 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 18) in 6 ms on localhost (3/3)
17/03/12 16:05:03 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
17/03/12 16:05:03 INFO DAGScheduler: ResultStage 7 (aggregate at WikipediaRanking.scala:35) finished in 0.027 s
17/03/12 16:05:03 INFO DAGScheduler: Job 7 finished: aggregate at WikipediaRanking.scala:35, took 0.035236 s
17/03/12 16:05:03 INFO SparkContext: Starting job: aggregate at WikipediaRanking.scala:35
17/03/12 16:05:03 INFO DAGScheduler: Got job 8 (aggregate at WikipediaRanking.scala:35) with 3 output partitions
17/03/12 16:05:03 INFO DAGScheduler: Final stage: ResultStage 8 (aggregate at WikipediaRanking.scala:35)
17/03/12 16:05:03 INFO DAGScheduler: Parents of final stage: List()
17/03/12 16:05:03 INFO DAGScheduler: Missing parents: List()
17/03/12 16:05:03 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[2] at map at WikipediaRanking.scala:25), which has no missing parents
17/03/12 16:05:03 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 3.8 KB, free 518.0 MB)
17/03/12 16:05:03 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.2 KB, free 518.0 MB)
17/03/12 16:05:03 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:60609 (size: 2.2 KB, free: 518.1 MB)
17/03/12 16:05:03 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1012
17/03/12 16:05:03 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 8 (MapPartitionsRDD[2] at map at WikipediaRanking.scala:25)
17/03/12 16:05:03 INFO TaskSchedulerImpl: Adding task set 8.0 with 3 tasks
17/03/12 16:05:03 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 19, localhost, partition 0, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 20, localhost, partition 1, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO Executor: Running task 0.0 in stage 8.0 (TID 19)
17/03/12 16:05:03 INFO Executor: Running task 1.0 in stage 8.0 (TID 20)
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_1 locally
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_0 locally
17/03/12 16:05:03 INFO Executor: Finished task 1.0 in stage 8.0 (TID 20). 953 bytes result sent to driver
17/03/12 16:05:03 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 21, localhost, partition 2, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO Executor: Finished task 0.0 in stage 8.0 (TID 19). 953 bytes result sent to driver
17/03/12 16:05:03 INFO Executor: Running task 2.0 in stage 8.0 (TID 21)
17/03/12 16:05:03 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 20) in 19 ms on localhost (1/3)
17/03/12 16:05:03 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 19) in 22 ms on localhost (2/3)
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_2 locally
17/03/12 16:05:03 INFO Executor: Finished task 2.0 in stage 8.0 (TID 21). 953 bytes result sent to driver
17/03/12 16:05:03 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 21) in 6 ms on localhost (3/3)
17/03/12 16:05:03 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
17/03/12 16:05:03 INFO DAGScheduler: ResultStage 8 (aggregate at WikipediaRanking.scala:35) finished in 0.027 s
17/03/12 16:05:03 INFO DAGScheduler: Job 8 finished: aggregate at WikipediaRanking.scala:35, took 0.036178 s
17/03/12 16:05:03 INFO SparkContext: Starting job: aggregate at WikipediaRanking.scala:35
17/03/12 16:05:03 INFO DAGScheduler: Got job 9 (aggregate at WikipediaRanking.scala:35) with 3 output partitions
17/03/12 16:05:03 INFO DAGScheduler: Final stage: ResultStage 9 (aggregate at WikipediaRanking.scala:35)
17/03/12 16:05:03 INFO DAGScheduler: Parents of final stage: List()
17/03/12 16:05:03 INFO DAGScheduler: Missing parents: List()
17/03/12 16:05:03 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[2] at map at WikipediaRanking.scala:25), which has no missing parents
17/03/12 16:05:03 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 3.8 KB, free 518.0 MB)
17/03/12 16:05:03 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.2 KB, free 518.0 MB)
17/03/12 16:05:03 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:60609 (size: 2.2 KB, free: 518.1 MB)
17/03/12 16:05:03 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1012
17/03/12 16:05:03 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 9 (MapPartitionsRDD[2] at map at WikipediaRanking.scala:25)
17/03/12 16:05:03 INFO TaskSchedulerImpl: Adding task set 9.0 with 3 tasks
17/03/12 16:05:03 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 22, localhost, partition 0, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 23, localhost, partition 1, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO Executor: Running task 0.0 in stage 9.0 (TID 22)
17/03/12 16:05:03 INFO Executor: Running task 1.0 in stage 9.0 (TID 23)
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_0 locally
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_1 locally
17/03/12 16:05:03 INFO Executor: Finished task 1.0 in stage 9.0 (TID 23). 953 bytes result sent to driver
17/03/12 16:05:03 INFO Executor: Finished task 0.0 in stage 9.0 (TID 22). 953 bytes result sent to driver
17/03/12 16:05:03 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 24, localhost, partition 2, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO Executor: Running task 2.0 in stage 9.0 (TID 24)
17/03/12 16:05:03 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 23) in 17 ms on localhost (1/3)
17/03/12 16:05:03 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 22) in 20 ms on localhost (2/3)
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_2 locally
17/03/12 16:05:03 INFO Executor: Finished task 2.0 in stage 9.0 (TID 24). 953 bytes result sent to driver
17/03/12 16:05:03 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 24) in 6 ms on localhost (3/3)
17/03/12 16:05:03 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
17/03/12 16:05:03 INFO DAGScheduler: ResultStage 9 (aggregate at WikipediaRanking.scala:35) finished in 0.024 s
17/03/12 16:05:03 INFO DAGScheduler: Job 9 finished: aggregate at WikipediaRanking.scala:35, took 0.031535 s
17/03/12 16:05:03 INFO SparkContext: Starting job: aggregate at WikipediaRanking.scala:35
17/03/12 16:05:03 INFO DAGScheduler: Got job 10 (aggregate at WikipediaRanking.scala:35) with 3 output partitions
17/03/12 16:05:03 INFO DAGScheduler: Final stage: ResultStage 10 (aggregate at WikipediaRanking.scala:35)
17/03/12 16:05:03 INFO DAGScheduler: Parents of final stage: List()
17/03/12 16:05:03 INFO DAGScheduler: Missing parents: List()
17/03/12 16:05:03 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[2] at map at WikipediaRanking.scala:25), which has no missing parents
17/03/12 16:05:03 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 3.8 KB, free 518.0 MB)
17/03/12 16:05:03 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.2 KB, free 518.0 MB)
17/03/12 16:05:03 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:60609 (size: 2.2 KB, free: 518.1 MB)
17/03/12 16:05:03 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1012
17/03/12 16:05:03 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 10 (MapPartitionsRDD[2] at map at WikipediaRanking.scala:25)
17/03/12 16:05:03 INFO TaskSchedulerImpl: Adding task set 10.0 with 3 tasks
17/03/12 16:05:03 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 25, localhost, partition 0, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 26, localhost, partition 1, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO Executor: Running task 1.0 in stage 10.0 (TID 26)
17/03/12 16:05:03 INFO Executor: Running task 0.0 in stage 10.0 (TID 25)
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_0 locally
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_1 locally
17/03/12 16:05:03 INFO Executor: Finished task 1.0 in stage 10.0 (TID 26). 953 bytes result sent to driver
17/03/12 16:05:03 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 27, localhost, partition 2, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO Executor: Running task 2.0 in stage 10.0 (TID 27)
17/03/12 16:05:03 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 26) in 23 ms on localhost (1/3)
17/03/12 16:05:03 INFO Executor: Finished task 0.0 in stage 10.0 (TID 25). 953 bytes result sent to driver
17/03/12 16:05:03 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 25) in 26 ms on localhost (2/3)
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_2 locally
17/03/12 16:05:03 INFO Executor: Finished task 2.0 in stage 10.0 (TID 27). 953 bytes result sent to driver
17/03/12 16:05:03 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 27) in 8 ms on localhost (3/3)
17/03/12 16:05:03 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool
17/03/12 16:05:03 INFO DAGScheduler: ResultStage 10 (aggregate at WikipediaRanking.scala:35) finished in 0.032 s
17/03/12 16:05:03 INFO DAGScheduler: Job 10 finished: aggregate at WikipediaRanking.scala:35, took 0.039129 s
17/03/12 16:05:03 INFO SparkContext: Starting job: aggregate at WikipediaRanking.scala:35
17/03/12 16:05:03 INFO DAGScheduler: Got job 11 (aggregate at WikipediaRanking.scala:35) with 3 output partitions
17/03/12 16:05:03 INFO DAGScheduler: Final stage: ResultStage 11 (aggregate at WikipediaRanking.scala:35)
17/03/12 16:05:03 INFO DAGScheduler: Parents of final stage: List()
17/03/12 16:05:03 INFO DAGScheduler: Missing parents: List()
17/03/12 16:05:03 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[2] at map at WikipediaRanking.scala:25), which has no missing parents
17/03/12 16:05:03 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 3.8 KB, free 517.9 MB)
17/03/12 16:05:03 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.2 KB, free 517.9 MB)
17/03/12 16:05:03 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:60609 (size: 2.2 KB, free: 518.1 MB)
17/03/12 16:05:03 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1012
17/03/12 16:05:03 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 11 (MapPartitionsRDD[2] at map at WikipediaRanking.scala:25)
17/03/12 16:05:03 INFO TaskSchedulerImpl: Adding task set 11.0 with 3 tasks
17/03/12 16:05:03 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 28, localhost, partition 0, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 29, localhost, partition 1, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO Executor: Running task 0.0 in stage 11.0 (TID 28)
17/03/12 16:05:03 INFO Executor: Running task 1.0 in stage 11.0 (TID 29)
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_0 locally
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_1 locally
17/03/12 16:05:03 INFO Executor: Finished task 0.0 in stage 11.0 (TID 28). 953 bytes result sent to driver
17/03/12 16:05:03 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 30, localhost, partition 2, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO Executor: Running task 2.0 in stage 11.0 (TID 30)
17/03/12 16:05:03 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 28) in 23 ms on localhost (1/3)
17/03/12 16:05:03 INFO Executor: Finished task 1.0 in stage 11.0 (TID 29). 953 bytes result sent to driver
17/03/12 16:05:03 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 29) in 24 ms on localhost (2/3)
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_2 locally
17/03/12 16:05:03 INFO Executor: Finished task 2.0 in stage 11.0 (TID 30). 953 bytes result sent to driver
17/03/12 16:05:03 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 30) in 7 ms on localhost (3/3)
17/03/12 16:05:03 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool
17/03/12 16:05:03 INFO DAGScheduler: ResultStage 11 (aggregate at WikipediaRanking.scala:35) finished in 0.031 s
17/03/12 16:05:03 INFO DAGScheduler: Job 11 finished: aggregate at WikipediaRanking.scala:35, took 0.038139 s
17/03/12 16:05:03 INFO SparkContext: Starting job: aggregate at WikipediaRanking.scala:35
17/03/12 16:05:03 INFO DAGScheduler: Got job 12 (aggregate at WikipediaRanking.scala:35) with 3 output partitions
17/03/12 16:05:03 INFO DAGScheduler: Final stage: ResultStage 12 (aggregate at WikipediaRanking.scala:35)
17/03/12 16:05:03 INFO DAGScheduler: Parents of final stage: List()
17/03/12 16:05:03 INFO DAGScheduler: Missing parents: List()
17/03/12 16:05:03 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[2] at map at WikipediaRanking.scala:25), which has no missing parents
17/03/12 16:05:03 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 3.8 KB, free 517.9 MB)
17/03/12 16:05:03 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.2 KB, free 517.9 MB)
17/03/12 16:05:03 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:60609 (size: 2.2 KB, free: 518.1 MB)
17/03/12 16:05:03 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1012
17/03/12 16:05:03 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 12 (MapPartitionsRDD[2] at map at WikipediaRanking.scala:25)
17/03/12 16:05:03 INFO TaskSchedulerImpl: Adding task set 12.0 with 3 tasks
17/03/12 16:05:03 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 31, localhost, partition 0, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 32, localhost, partition 1, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO Executor: Running task 0.0 in stage 12.0 (TID 31)
17/03/12 16:05:03 INFO Executor: Running task 1.0 in stage 12.0 (TID 32)
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_0 locally
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_1 locally
17/03/12 16:05:03 INFO Executor: Finished task 0.0 in stage 12.0 (TID 31). 953 bytes result sent to driver
17/03/12 16:05:03 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 33, localhost, partition 2, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO Executor: Running task 2.0 in stage 12.0 (TID 33)
17/03/12 16:05:03 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 31) in 18 ms on localhost (1/3)
17/03/12 16:05:03 INFO Executor: Finished task 1.0 in stage 12.0 (TID 32). 953 bytes result sent to driver
17/03/12 16:05:03 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 32) in 18 ms on localhost (2/3)
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_2 locally
17/03/12 16:05:03 INFO Executor: Finished task 2.0 in stage 12.0 (TID 33). 953 bytes result sent to driver
17/03/12 16:05:03 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 33) in 7 ms on localhost (3/3)
17/03/12 16:05:03 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool
17/03/12 16:05:03 INFO DAGScheduler: ResultStage 12 (aggregate at WikipediaRanking.scala:35) finished in 0.024 s
17/03/12 16:05:03 INFO DAGScheduler: Job 12 finished: aggregate at WikipediaRanking.scala:35, took 0.033862 s
17/03/12 16:05:03 INFO SparkContext: Starting job: aggregate at WikipediaRanking.scala:35
17/03/12 16:05:03 INFO DAGScheduler: Got job 13 (aggregate at WikipediaRanking.scala:35) with 3 output partitions
17/03/12 16:05:03 INFO DAGScheduler: Final stage: ResultStage 13 (aggregate at WikipediaRanking.scala:35)
17/03/12 16:05:03 INFO DAGScheduler: Parents of final stage: List()
17/03/12 16:05:03 INFO DAGScheduler: Missing parents: List()
17/03/12 16:05:03 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[2] at map at WikipediaRanking.scala:25), which has no missing parents
17/03/12 16:05:03 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 3.8 KB, free 517.9 MB)
17/03/12 16:05:03 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.2 KB, free 517.9 MB)
17/03/12 16:05:03 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:60609 (size: 2.2 KB, free: 518.1 MB)
17/03/12 16:05:03 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1012
17/03/12 16:05:03 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 13 (MapPartitionsRDD[2] at map at WikipediaRanking.scala:25)
17/03/12 16:05:03 INFO TaskSchedulerImpl: Adding task set 13.0 with 3 tasks
17/03/12 16:05:03 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 34, localhost, partition 0, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 35, localhost, partition 1, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO Executor: Running task 0.0 in stage 13.0 (TID 34)
17/03/12 16:05:03 INFO Executor: Running task 1.0 in stage 13.0 (TID 35)
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_1 locally
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_0 locally
17/03/12 16:05:03 INFO Executor: Finished task 1.0 in stage 13.0 (TID 35). 953 bytes result sent to driver
17/03/12 16:05:03 INFO Executor: Finished task 0.0 in stage 13.0 (TID 34). 953 bytes result sent to driver
17/03/12 16:05:03 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 36, localhost, partition 2, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO Executor: Running task 2.0 in stage 13.0 (TID 36)
17/03/12 16:05:03 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 35) in 26 ms on localhost (1/3)
17/03/12 16:05:03 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 34) in 28 ms on localhost (2/3)
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_2 locally
17/03/12 16:05:03 INFO Executor: Finished task 2.0 in stage 13.0 (TID 36). 953 bytes result sent to driver
17/03/12 16:05:03 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 36) in 8 ms on localhost (3/3)
17/03/12 16:05:03 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool
17/03/12 16:05:03 INFO DAGScheduler: ResultStage 13 (aggregate at WikipediaRanking.scala:35) finished in 0.034 s
17/03/12 16:05:03 INFO DAGScheduler: Job 13 finished: aggregate at WikipediaRanking.scala:35, took 0.040553 s
17/03/12 16:05:03 INFO SparkContext: Starting job: aggregate at WikipediaRanking.scala:35
17/03/12 16:05:03 INFO DAGScheduler: Got job 14 (aggregate at WikipediaRanking.scala:35) with 3 output partitions
17/03/12 16:05:03 INFO DAGScheduler: Final stage: ResultStage 14 (aggregate at WikipediaRanking.scala:35)
17/03/12 16:05:03 INFO DAGScheduler: Parents of final stage: List()
17/03/12 16:05:03 INFO DAGScheduler: Missing parents: List()
17/03/12 16:05:03 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[2] at map at WikipediaRanking.scala:25), which has no missing parents
17/03/12 16:05:03 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 3.8 KB, free 517.9 MB)
17/03/12 16:05:03 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 2.2 KB, free 517.9 MB)
17/03/12 16:05:03 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:60609 (size: 2.2 KB, free: 518.1 MB)
17/03/12 16:05:03 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1012
17/03/12 16:05:03 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 14 (MapPartitionsRDD[2] at map at WikipediaRanking.scala:25)
17/03/12 16:05:03 INFO TaskSchedulerImpl: Adding task set 14.0 with 3 tasks
17/03/12 16:05:03 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 37, localhost, partition 0, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 38, localhost, partition 1, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO Executor: Running task 0.0 in stage 14.0 (TID 37)
17/03/12 16:05:03 INFO Executor: Running task 1.0 in stage 14.0 (TID 38)
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_0 locally
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_1 locally
17/03/12 16:05:03 INFO Executor: Finished task 0.0 in stage 14.0 (TID 37). 953 bytes result sent to driver
17/03/12 16:05:03 INFO Executor: Finished task 1.0 in stage 14.0 (TID 38). 953 bytes result sent to driver
17/03/12 16:05:03 INFO TaskSetManager: Starting task 2.0 in stage 14.0 (TID 39, localhost, partition 2, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO Executor: Running task 2.0 in stage 14.0 (TID 39)
17/03/12 16:05:03 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 37) in 25 ms on localhost (1/3)
17/03/12 16:05:03 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 38) in 25 ms on localhost (2/3)
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_2 locally
17/03/12 16:05:03 INFO Executor: Finished task 2.0 in stage 14.0 (TID 39). 953 bytes result sent to driver
17/03/12 16:05:03 INFO TaskSetManager: Finished task 2.0 in stage 14.0 (TID 39) in 7 ms on localhost (3/3)
17/03/12 16:05:03 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool
17/03/12 16:05:03 INFO DAGScheduler: ResultStage 14 (aggregate at WikipediaRanking.scala:35) finished in 0.032 s
17/03/12 16:05:03 INFO DAGScheduler: Job 14 finished: aggregate at WikipediaRanking.scala:35, took 0.038181 s
17/03/12 16:05:03 INFO SparkContext: Starting job: aggregate at WikipediaRanking.scala:35
17/03/12 16:05:03 INFO DAGScheduler: Got job 15 (aggregate at WikipediaRanking.scala:35) with 3 output partitions
17/03/12 16:05:03 INFO DAGScheduler: Final stage: ResultStage 15 (aggregate at WikipediaRanking.scala:35)
17/03/12 16:05:03 INFO DAGScheduler: Parents of final stage: List()
17/03/12 16:05:03 INFO DAGScheduler: Missing parents: List()
17/03/12 16:05:03 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[2] at map at WikipediaRanking.scala:25), which has no missing parents
17/03/12 16:05:03 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 3.8 KB, free 517.9 MB)
17/03/12 16:05:03 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 2.2 KB, free 517.9 MB)
17/03/12 16:05:03 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:60609 (size: 2.2 KB, free: 518.1 MB)
17/03/12 16:05:03 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1012
17/03/12 16:05:03 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 15 (MapPartitionsRDD[2] at map at WikipediaRanking.scala:25)
17/03/12 16:05:03 INFO TaskSchedulerImpl: Adding task set 15.0 with 3 tasks
17/03/12 16:05:03 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 40, localhost, partition 0, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 41, localhost, partition 1, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO Executor: Running task 1.0 in stage 15.0 (TID 41)
17/03/12 16:05:03 INFO Executor: Running task 0.0 in stage 15.0 (TID 40)
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_1 locally
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_0 locally
17/03/12 16:05:03 INFO Executor: Finished task 1.0 in stage 15.0 (TID 41). 953 bytes result sent to driver
17/03/12 16:05:03 INFO Executor: Finished task 0.0 in stage 15.0 (TID 40). 953 bytes result sent to driver
17/03/12 16:05:03 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 42, localhost, partition 2, PROCESS_LOCAL, 5430 bytes)
17/03/12 16:05:03 INFO Executor: Running task 2.0 in stage 15.0 (TID 42)
17/03/12 16:05:03 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 41) in 25 ms on localhost (1/3)
17/03/12 16:05:03 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 40) in 28 ms on localhost (2/3)
17/03/12 16:05:03 INFO BlockManager: Found block rdd_2_2 locally
17/03/12 16:05:03 INFO Executor: Finished task 2.0 in stage 15.0 (TID 42). 953 bytes result sent to driver
17/03/12 16:05:03 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 42) in 8 ms on localhost (3/3)
17/03/12 16:05:03 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool
17/03/12 16:05:03 INFO DAGScheduler: ResultStage 15 (aggregate at WikipediaRanking.scala:35) finished in 0.035 s
17/03/12 16:05:03 INFO DAGScheduler: Job 15 finished: aggregate at WikipediaRanking.scala:35, took 0.040554 s
17/03/12 16:05:03 INFO SparkContext: Starting job: aggregate at WikipediaRanking.scala:35
17/03/12 16:05:03 INFO DAGScheduler: Got job 16 (aggregate at WikipediaRanking.scala:35) with 3 output partitions
17/03/12 16:05:03 INFO DAGScheduler: Final stage: ResultStage 16 (aggregate at WikipediaRanking.scala:35)
17/03/12 16:05:03 INFO DAGScheduler: Parents of final stage: List()
17/03/12 16:05:03 INFO DAGScheduler: Missing parents: List()
17/03/12 16:05:03 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[2] at map at WikipediaRanking.scala:25), which has no missing parents
17/03/12 16:05:03 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 3.8 KB, free 517.9 MB)
17/03/12 16:05:03 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:60609 in memory (size: 2.2 KB, free: 518.1 MB)
17/03/12 16:05:03 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 2.2 KB, free 517.9 MB)
17/03/12 16:05:03 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:60609 in memory (size: 2.2 KB, free: 518.1 MB)
17/03/12 16:05:03 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:60609 (size: 2.2 KB, free: 518.1 MB)
17/03/12 16:05:03 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1012
17/03/12 16:05:03 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 16 (MapPartitionsRDD[2] at map at WikipediaRanking.scala:25)
17/03/12 16:05:03 INFO TaskSchedulerImpl: Adding task set 16.0 with 3 tasks
17/03/12 16:05:03 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:60609 in memory (size: 2.2 KB, free: 518.1 MB)
17/03/12 16:05:03 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1
[Feedback clipped, Coursera doesn't allow us to display more than 64kb of feedback]